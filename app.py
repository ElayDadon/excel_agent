# app.py (专住 转)
import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.generativeai import types

# =======================================================================
# ====>  拽 爪转 注砖 
# =======================================================================

def create_gemini_client(api_key):
    """
    爪专 拽 Client 砖 Gemini.
    拽专 砖 爪, 专 (client, None).
    拽专 砖 砖, 专 (None, error_message_string).
    """
    try:
        client = genai.Client(api_key=api_key)
        return client, None
    except Exception as e:
        error_message = str(e)
        return None, error_message

def get_response_from_gemini(client, dataframe, query, chat_history):
    """砖 拽砖 -Gemini 爪注转 拽 -Client."""
    if not client:
        return "Error: Gemini client is not initialized."

    model = "gemini-2.0-flash"
    df_columns = dataframe.columns.tolist()
    prompt_text = f"""
    You are a world-class, friendly, and conversational data analyst AI.
    Your main goal is to help a user understand their data by answering questions in natural Hebrew.
    You specialize in Python with pandas and Plotly.

    **CONTEXT:**
    - You have access to a pandas DataFrame named `df` with the following columns: {df_columns}.
    - The user's current query is: "{query}"
    - The recent conversation history is: {chat_history}

    **YOUR CORE PRINCIPLES:**
    1.  **Be Conversational and Proactive:** When first asked "what is in the file" (e.g., " 砖 拽抓"), provide a comprehensive text-only overview.
    2.  **Understand User Intent & Handle Typos:** Your top priority is to understand what the user *means*, not just what they typed. (e.g., "拽抓" -> "拽抓").
    3.  **Handle Ambiguity:** If a query is vague like "转住驻拽 ", use the immediate preceding context.

    **RESPONSE FORMATTING (Strictly follow this):**
    - To generate pandas code for data/analysis, wrap it in ```python\\n[CODE]\\n...```
    - To generate Plotly code for a graph, wrap it in ```python\\n[PLOT]\\n...```
    - For conversational text answers, respond directly without any wrappers.
    """

    contents = [types.Content(role="user", parts=[types.Part.from_text(text=prompt_text)])]

    try:
        response = client.models.generate_content(model=f"models/{model}", contents=contents)
        return response.text
    except Exception as e:
        return f"Error communicating with Gemini: {e}"

def execute_code(dataframe, gemini_response):
    """专抓 转 拽 砖转拽 驻 ."""
    response_text = gemini_response.strip().replace("`", "")
    if "python\\n[CODE]" in response_text:
        code_to_run = response_text.split("python\\n[CODE]")[1].strip()
        try:
            result = eval(code_to_run, {"df": dataframe, "pd": pd})
            return {"type": "data", "content": result}
        except Exception as e:
            return {"type": "error", "content": f"砖 专爪转 拽 转: {e}\\n拽: {code_to_run}"}
    elif "python\\n[PLOT]" in response_text:
        code_to_run = response_text.split("python\\n[PLOT]")[1].strip()
        try:
            local_scope = {"df": dataframe}
            exec(code_to_run, globals(), local_scope)
            fig = local_scope.get('fig', None)
            if fig:
                return {"type": "plot", "content": fig}
            else:
                return {"type": "error", "content": "拽 专祝  爪专 砖转 砖 'fig'."}
        except Exception as e:
            return {"type": "error", "content": f"砖 爪专转 专祝: {e}\\n拽: {code_to_run}"}
    else:
        return {"type": "text", "content": response_text}

# =======================================================================
# ====> 砖拽 砖转砖 砖 Streamlit 转 
# =======================================================================

# --- 拽专 转 砖 驻转 -Streamlit Secrets ---
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")

st.set_page_config(layout="wide", page_title="Agent 转 转")

# 转 砖转
if "messages" not in st.session_state:
    st.session_state.messages = []
if "dataframe" not in st.session_state:
    st.session_state.dataframe = None
if "gemini_client" not in st.session_state:
    st.session_state.gemini_client = None
if "client_error" not in st.session_state:
    st.session_state.client_error = None

st.sidebar.title("专转")
st.sidebar.header("注转 拽抓 Excel")
uploaded_file = st.sidebar.file_uploader("专 拽抓", type=["xlsx", "xls"])

if uploaded_file is not None:
    if st.session_state.dataframe is None:
        with st.spinner("注 转 转..."):
            st.session_state.dataframe = pd.read_excel(uploaded_file)
            st.session_state.messages = []
            st.sidebar.success("拽抓 注 爪!")

st.title(" Agent 拽爪注 转 转")
st.write("注 拽抓 拽住 爪 ,  转 砖 砖转 注 转 砖.")

# --- 拽转 转 API 砖专转 注 爪转 砖转 ---
if st.session_state.gemini_client is None and st.session_state.client_error is None:
    if not GEMINI_API_KEY:
        st.session_state.client_error = "砖: 驻转 -API 砖 Gemini  专 -Secrets 砖 驻拽爪."
    else:
        client, error_message = create_gemini_client(GEMINI_API_KEY)
        if error_message:
            st.session_state.client_error = f"专注 砖 转  Google:\n\n```\n{error_message}\n```"
        else:
            st.session_state.gemini_client = client

# --- 转爪 专砖转 ---
if st.session_state.client_error:
    st.error(st.session_state.client_error)
elif st.session_state.dataframe is None:
    st.info(" 注 拽抓 拽住  转 转 砖.")
else:
    # 爪转 住专转 爪'
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["type"] == "data":
                st.dataframe(message["content"])
            elif message["type"] == "plot":
                st.plotly_chart(message["content"])
            else:
                st.markdown(message["content"])
    
    # 拽转 拽 砖转砖
    if prompt := st.chat_input("砖 转  专 注 转..."):
        st.session_state.messages.append({"role": "user", "type": "text", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("砖..."):
                gemini_response = get_response_from_gemini(st.session_state.gemini_client, st.session_state.dataframe, prompt, st.session_state.messages)
                result = execute_code(st.session_state.dataframe, gemini_response)
                if result["type"] == "data":
                    st.dataframe(result["content"])
                elif result["type"] == "plot":
                    st.plotly_chart(result["content"])
                else:
                    st.markdown(result["content"])
                st.session_state.messages.append({"role": "assistant", **result})